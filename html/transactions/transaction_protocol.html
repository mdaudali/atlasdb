<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Transaction Protocol &mdash; OSS AtlasDB develop documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/release-notes.css?v=b943762f" />
      <link rel="stylesheet" type="text/css" href="../_static/theme_overrides.css?v=fd4cc2db" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=4191f987"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Life of a Transaction" href="life_of_a_transaction.html" />
    <link rel="prev" title="Performance Ideas" href="performance_ideas.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            OSS AtlasDB
          </a>
              <div class="version">
                develop
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview/index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../schemas/index.html">Schemas</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Transactions</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="isolation_levels.html">Isolation Levels</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_ideas.html">Performance Ideas</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Transaction Protocol</a></li>
<li class="toctree-l2"><a class="reference internal" href="life_of_a_transaction.html">Life of a Transaction</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../configuration/index.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cluster_management/index.html">Cluster Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../services/index.html">Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance/index.html">Performance Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../miscellaneous/index.html">Miscellaneous</a></li>
<li class="toctree-l1"><a class="reference internal" href="../troubleshooting/index.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release_notes/index.html">Releases</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OSS AtlasDB</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Transactions</a></li>
      <li class="breadcrumb-item active">Transaction Protocol</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/palantir/atlasdb/blob/develop/docs/source/transactions/transaction_protocol.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="transaction-protocol">
<span id="id1"></span><h1>Transaction Protocol<a class="headerlink" href="#transaction-protocol" title="Permalink to this heading"></a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The AtlasDB transaction protocol is inspired by, but different from
Google’s Percolator transaction protocol. For additional reading,
please see <a class="reference external" href="http://research.google.com/pubs/pub36726.html">Percolator</a>.</p>
</div>
<p>AtlasDB is a standard multi-version concurrency control (MVCC) Snapshot Isolation
protocol. Each transaction has a start timestamp and a commit timestamp. You can view all rows that
have a commit timestamp less than your start timestamp. You will get a
write-write conflict for any cells that you write that were modified in transactions
that committed at a timestamp between your start timestamp and your
commit timestamp.</p>
<section id="write-protocol">
<h2>Write Protocol<a class="headerlink" href="#write-protocol" title="Permalink to this heading"></a></h2>
<ol class="arabic simple">
<li><p>Complete all reads using the transaction’s start timestamp.  This is necessary to
determine the writes required by the transaction. Buffer writes in memory
until commit time.</p></li>
<li><p>At commit time we grab
row locks for all the rows we are about to write (this is to detect
write/write conflicts). We also grab the start timestamp row lock for
the Transaction table.</p></li>
<li><p>Now that we have our locks we check for write/write conflicts. If any
cell has been modified by a transaction that committed after our
startTs then we have a write conflict.</p></li>
<li><p>Write the data to the KV store with TS = startTs.</p></li>
<li><p>Now we get a fresh commit timestamp.</p></li>
<li><p>Then (this is important) we make sure our locks are still valid. If
our locks expire after this point that is ok, but they have to be
valid now.</p></li>
<li><p>Then we atomically do a “putUnlessExists” into the transaction table
with our commit timestamp.</p></li>
<li><p>Unlock the locks.</p></li>
</ol>
</section>
<section id="read-protocol">
<h2>Read Protocol<a class="headerlink" href="#read-protocol" title="Permalink to this heading"></a></h2>
<p>Let’s assume we are reading Cell c.</p>
<ol class="arabic">
<li><p>Read from the KV store and get the most recent data with TS &lt;
startTs.</p></li>
<li><p>Get a read lock on the transaction row for c.startTs (not needed if
c.startTs is less than immutableTs). This is to wait to make sure
the transaction that wrote it is done.</p></li>
<li><p>Read the transaction table for the commitTs.</p></li>
<li><p>One of two actions:</p>
<p>a. If commitTs doesn’t exist, try to roll back this transaction and
start over. If it is -1 (been rolled back), delete the associated data
and start over.</p>
<p>b. If c.commitTs greater than your startTs, skip it and move on to the
next highest TS for the cell.</p>
</li>
</ol>
</section>
<section id="immutable-timestamp">
<h2>Immutable Timestamp<a class="headerlink" href="#immutable-timestamp" title="Permalink to this heading"></a></h2>
<p>The point in time right before the oldest currently executing
transaction is referred to as the immutable timestamp. This is because
nothing before this point in time will change. (All writes are available
to read and are either committed or pending commit.)</p>
<p>Any timestamp before the oldest open transaction’s start timestamp may
be called the immutable timestamp, but generally it refers to the most
recent TS for which this is true.</p>
<p>To implement this we grab a new TS (PRE_START_TS) and lock that before
we begin our transaction. We have a feature in the lock server to return
the minLockedInVersion. If PRE_START_TS is the oldest, then lock
server will return this as the minLockedVersion. The write protocol
ensures that this lock is still held after writes are done to the
underlying store. This is the only part of the lock server that doesn’t
shard well because we have to get the global min. However we can just
ask each lock server what its min is and take the global min. We can
also cache this value for a bit and we don’t have to recompute it each
time. Normally clients don’t need the absolute most recent
ImmutableTs, but just a relatively modern one.</p>
<p>Tricky points regarding the immutable timestamp:</p>
<ul class="simple">
<li><p>A transaction with startTs &lt; immutableTs may be stuck on the
putUnlessExists part of its commit (its locks are timed out,
otherwise immutableTs &lt; startTs). This is ok because if we read
any of its values we will try to roll back their transaction and we
will either see it as committed or failed, but either way it will be
complete.</p></li>
<li><p>The immutable timestamp is not guaranteed to be strictly increasing.
This is because the action of grabbing PRE_START_TS and the action
of locking it are not performed together atomically. This doesn’t
cause correctness issues, though, since we wait until we have locked
PRE_START_TS before grabbing our start timestamp. For example, if
the current immutable timestamp is immutableTs1 and transaction T
locks in a lower value immutableTs0, then T’s startTs must be
greater than immutableTs1, so any readers who grabbed
immutableTs1 will still grab locks when trying to read rows
written by T.</p></li>
</ul>
</section>
<section id="cleaning-up-old-values">
<h2>Cleaning Up Old Values<a class="headerlink" href="#cleaning-up-old-values" title="Permalink to this heading"></a></h2>
<p>Since we are doing away with historical transactions, we can clean up
old values. We are still allowing long running read transactions, but we
should cap them so they can only run for a couple days or weeks. This
means that we can go through and clean up old values if they have been
written over for at least x days (let’s just say 10 days for now).</p>
<p>One issue is that we don’t have a mapping from TS to real time. Also we
don’t trust real time anywhere else and don’t plan to start now. We can
take a ts every hour or so and pick one before 10 days ago. This does
impose a small relationship to “time” but we will mitigate it in the
next paragraph.</p>
<p>What if we have a reader that is still reading but is very old (before
10 days ago (or so we think))? We solve this case by writing a dummy
value for a Cell we are going to clean up with a negative timestamp and
then cleaning up old rows from oldest to newest. This means that if you
are still reading and stumble on a row that has been cleaned that you
would have read, then you will read a row with a negative TS which will
get turned into a TooOldReaderException (which is a retriable
exception). This ensures that we can do cleanup of old values safely
even in the presence of arbitrarily old readers.</p>
<p>If we want to support reading of values older than “10 days” then these
readers will have to start reserving more time to push out cleanup up
old values. Basically every so often a long running read should “check
in” which will ensure old values won’t get cleaned up out from under it
for another day or so. Note this cleanup has implications with respect
to hard delete and we may want to force a cleanup sooner and allow these
long running reads to fail in the name of hard delete.</p>
</section>
<section id="cleaning-up-old-nonce-values">
<h2>Cleaning up old nonce values<a class="headerlink" href="#cleaning-up-old-nonce-values" title="Permalink to this heading"></a></h2>
<p>Part of doing cleanup is writing an empty value at a negative timestamp
for some cell. This works to prevent old read only transactions from
reading empty value when really they should have read a cleaned value.
However these negative timestamp values can build up and take up a lot
of space and also make range scans really slow if the whole table is
full of these nonce values.</p>
<p>For specific tables we allow these old nonce values to be removed from
the KV store, but at the cost of never being able to read this table in
a read-only transaction. This seems like a good trade-off and lets us
build indexes with status variables and be able to delete old values
completely and still support range scans.</p>
</section>
<section id="read-write-conflicts">
<h2>Read/Write Conflicts<a class="headerlink" href="#read-write-conflicts" title="Permalink to this heading"></a></h2>
<p>The transaction protocol has write/write conflicts built into it. If two
transactions touch the same cell, one will be rolled back (as long as the
table does write/write conflict detection (which is the default)). What
if a user wanted some way to set up read write locks. This can be built
into the protocol fairly easily. Currently a table can be set up either
to ignore all conflicts or to have write/write conflicts. There is a
third option we can do called read_write_conflicts. The semantics we
want are if your transaction reads a value and a new (different) value
for this cell has been committed then we should rollback. Similarly if
you write a value and an already committed transaction read the value
then you should retry.</p>
<p>The way we accomplish this is very similar to write/write conflicts. If
we are storing back the same value we read (read side of the
read/write), then we are looking for transactions that committed after
our start that wrote a different value to this cell. If we are writing a
new value (write side) then we should roll back if we see any new
commited rows regardless of if they are different than what was there
before.</p>
<p>This could be used to implement acl changes for objects that don’t
require locking for the duration of the transaction. We could just have
a table set up as READ_WRITE_CONFLICTS and in this table we have a row
for each object with a counter in it. Every time there is a security
change to an object we increment this counter. Every time we do any
other write operation to this object we read and touch this counter.</p>
<p>The main problem with read/write conflicts if that you can’t control the
fairness of these transactions. If read operations keep coming in and
are fast then a write operation may keep retrying and get starved and
never complete.</p>
<p>The easiest way to implement this read/write conflict would be to check
the last value that was successfully committed to the cell and see if it
was equal to the value being stored. This way if you are just doing a touch you
are basically checking that the last committer put the value that you
are storing. This will work the same as a compare and swap check. This
version is more scalable because you only have to check the most recent
successful commit and not all commits after your start time. The
downside if you don’t get true read/write exclusion, you basically just
get CAS semantics. This isn’t a big deal because using a counter is the
most common way to use this type of exclusion anyway.</p>
</section>
<section id="proof-of-correctness">
<h2>Proof of Correctness<a class="headerlink" href="#proof-of-correctness" title="Permalink to this heading"></a></h2>
<p>If we want to prove that this protocol works this means that we need to
show that we read precisely the data committed before the start of our
transaction. We proceed by showing that:</p>
<ol class="arabic simple">
<li><p>We read data from any writes that committed before our transaction started.</p></li>
<li><p>We do not read any writes that commit after our transaction started
(even if the relevant transactions started before our transaction started).</p></li>
<li><p>We do not read any writes from a failed transaction.</p></li>
</ol>
<section id="reading-all-writes-before-transaction-start">
<h3>Reading All Writes Before Transaction Start<a class="headerlink" href="#reading-all-writes-before-transaction-start" title="Permalink to this heading"></a></h3>
<p>We must ensure writes committed before our start are read. If we look at
the write protocol then we know that all writes are complete to the KV
store THEN get a commit timestamp and THEN verify our locks are still
valid. Then it proceeds to putUnlessExists to the transaction table.</p>
<p>This means that if a commitTs is less than our startTs then the KV store
will already have these rows written. We require that the underlying KV
store has durable writes so these rows will be read.</p>
</section>
<section id="lock-timeouts-after-validation">
<h3>Lock Timeouts After Validation<a class="headerlink" href="#lock-timeouts-after-validation" title="Permalink to this heading"></a></h3>
<p>What if locks time out after we do the check that they are still valid?
If locks time out while writing to the transaction table we depend on
the putUnlessExists to arbitrate whether a transaction is committed or
not. If the transaction hangs while trying to commit then it is possible
a reader will come roll it back. In this case we will need to retry our
transaction, but we don’t expect this to happen in normal cases. If the
lock server is restarted and forgets all its locks then this becomes
more likely. This means that the transaction table must have strong
consistency guarantees, but the rest of the system only has to have
durable writes. The standard way of getting this level of consistency is
to use a write ahead log to know what has/hasn’t been committed.
Bookkeeper is an example of a project that implements this kind of log.</p>
</section>
<section id="ignoring-writes-committed-after-transaction-start">
<h3>Ignoring Writes Committed After Transaction Start<a class="headerlink" href="#ignoring-writes-committed-after-transaction-start" title="Permalink to this heading"></a></h3>
<p>We need to ensure that writes committed after our startTs are not read.
If we get back a row from the KV store then we know that the txn that
wrote it has a startTs less than ours, but it may still be in progress
or committed. We postfilter on the transaction table. If we find that
the locks for this txn are no longer held, but there still isn’t a row
in the transaction table, then we force it to be rolled back. This will
ensure that when the txn tries to commit then it will fail and have to
retry. If our rollback fails because txn did actually commit then we
read that value and carry on. We can retry until the value is there, but
usually we just throw and retry the current transaction if there is a
remoting failure.</p>
</section>
<section id="ignoring-failed-transactions">
<h3>Ignoring Failed Transactions<a class="headerlink" href="#ignoring-failed-transactions" title="Permalink to this heading"></a></h3>
<p>This is achieved because we post-filter all reads through the
transaction table. If we find that transaction is rolled back, then we
just delete it and retry the read.</p>
</section>
</section>
<section id="non-obvious-semantics">
<h2>Non-Obvious Semantics<a class="headerlink" href="#non-obvious-semantics" title="Permalink to this heading"></a></h2>
<section id="read-rollbacks">
<h3>Read Rollbacks<a class="headerlink" href="#read-rollbacks" title="Permalink to this heading"></a></h3>
<p>Reads must rollback transactions they find that are uncommitted. If a
read doesn’t go out of its way to roll back an uncommitted row and just
skips it and keeps looking in the past for a committed row, then it
cannot be sure that this row doesn’t get committed later. The committing
transaction may be stuck right before the “putUnlessExists” part of the
write protocol. If this is the case, we can’t be sure that transaction
isn’t going to have a commit timestamp before our start timestamp, so we
have to make sure this transaction will be failed for sure before we can
skip past it.</p>
</section>
</section>
<section id="serializable-isolation">
<h2>Serializable Isolation<a class="headerlink" href="#serializable-isolation" title="Permalink to this heading"></a></h2>
<p>AtlasDB can be extended to have serializable isolation semantics.
Basically instead of looking at your write set and detecting writes that
commit in between your start and commit timestamps we should look at the
read set and detect writes the same way. The only tricky bit is handling
range scans. There are a few proofs that removing this read-write
conflict is sufficient to achieve serializability. The simplest proof is
from “A Critique of Snapshot Isolation” and basically states that if you
remove all writes that could commit between your start and commitTs,
then you can make a serial ordering by just compressing down all the
actions of a transaction to happen right before its commit timestamp.
This works because all reads you do will be the same at the startTs as
they are at the commitTs.</p>
<p>Removing read-write conflicts is sufficient to get serializability if
every single transaction does this. However sometimes it is desirable to
run with a mix of SI and SSI. This means that transactions that choose
Serializable should also check for write-write conflict so they are
compatible with SI transactions.</p>
<p>One of the best features of Serializable Isolation is that you get true
linearizability. Each transaction can be treated like it is just
happened instantaneously at its commit timestamp and all invariants hold
at all times.</p>
<p>The main downside to this approach is that all the reads need to be done
after the commit timestamp is allocated and therefore after all the
writes are done to the underlying store. What this means is that other
transactions may have to block on these written values while we do reads
to ensure they haven’t changed. The good news is that the only times a
transaction would wait is if it could have a read-write conflict. This
means that the waiting may result in a rollback anyway so waiting isn’t
a huge hit. To mitigate this issue we should make transactions that
write hot rows not have a huge read set that needs to be verified.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="performance_ideas.html" class="btn btn-neutral float-left" title="Performance Ideas" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="life_of_a_transaction.html" class="btn btn-neutral float-right" title="Life of a Transaction" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Palantir Technologies.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>